[ğŸ  Accueil](../index.md) | [ğŸ“‹ Sommaire](../sommaire.md) | [ğŸ“– Lexique](lexique.md) | [â¬…ï¸ PrÃ©cÃ©dent](02-jvm-platform-threads.md) | [â¡ï¸ Suivant](04-virtual-threads-intro.md)

---

# 3. Limitations RÃ©elles des Platform Threads

## 3.1 Le problÃ¨me fondamental : Thread-per-Request

### Architecture classique d'un serveur

```
Serveur HTTP classique (Tomcat, Jetty, etc.)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Thread Pool (200 threads)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  Client 1 â†’ [Thread 1] â†’ Handler â†’ Response     â”‚
â”‚  Client 2 â†’ [Thread 2] â†’ Handler â†’ Response     â”‚
â”‚  Client 3 â†’ [Thread 3] â†’ Handler â†’ Response     â”‚
â”‚  ...                                            â”‚
â”‚  Client 200 â†’ [Thread 200] â†’ Handler â†’ Response â”‚
â”‚                                                 â”‚
â”‚   Client 201 â†’ [QUEUE] En attente...            â”‚
â”‚   Client 202 â†’ [QUEUE] En attente...            |
â”‚   Client 203 â†’ [QUEUE] En attente...            |
â”‚                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ProblÃ¨me:
â€¢ 200 threads max = 200 requÃªtes simultanÃ©es max
â€¢ Au-delÃ : les requÃªtes attendent dans une queue
â€¢ Si tous les threads sont bloquÃ©s en I/O â†’ CPU Ã  5%
â€¢ Mais impossible d'accepter plus de clients!
```

### DÃ©monstration avec un serveur HTTP simple

Ici, on va crÃ©er un serveur HTTP simple en Java qui utilise un ThreadPoolExecutor avec une taille de pool limitÃ©e et une queue limitÃ©e. 
Le serveur simule un traitement bloquant (par exemple, une opÃ©ration I/O) en dormant pendant 5 secondes pour chaque requÃªte. 
En parallÃ¨le on va jouer un petit script pour envoyer 30 requÃªtes simultanÃ©es et observer le comportement du serveur.

```java
import com.sun.net.httpserver.HttpServer;

public class ThreadPerRequestDemo {

	private static final AtomicInteger activeRequests = new AtomicInteger(0);
	private static final AtomicInteger rejectedRequests = new AtomicInteger(0);

	public static void main(String[] args) throws IOException {

		HttpServer server = HttpServer.create(new InetSocketAddress(8080), 0);

		ThreadPoolExecutor executor = new ThreadPoolExecutor(
			5,
			5,
			60L, TimeUnit.SECONDS,
			new ArrayBlockingQueue<>(10)
		);

		executor.setRejectedExecutionHandler((r, exec) -> {
			int rejected = rejectedRequests.incrementAndGet();
			System.err.printf("âŒ REJETÃ‰ ! Total rejections: %d%n", rejected);
			throw new RejectedExecutionException("Queue pleine");
		});

		server.setExecutor(executor);

		// Handler qui simule un I/O bloquant
		server.createContext("/api/data", exchange -> {
			int active = activeRequests.incrementAndGet();
			int queued = executor.getQueue().size();
			String threadName = Thread.currentThread().getName();

			System.out.printf("[%s] RequÃªte reÃ§ue (Active: %d, Queue: %d)%n",
				threadName, active, queued);

			try {
				Thread.sleep(5000);

				String response = String.format(
					"TraitÃ© par %s (Active: %d, Queue: %d)",
					threadName, active, queued
				);

				exchange.sendResponseHeaders(200, response.length());
				OutputStream os = exchange.getResponseBody();
				os.write(response.getBytes());
				os.close();

			} catch (InterruptedException e) {
				Thread.currentThread().interrupt();
			} finally {
				activeRequests.decrementAndGet();
			}
		});

		// Endpoint de monitoring amÃ©liorÃ©
		server.createContext("/stats", exchange -> {
			String stats = String.format(
				"Active: %d, Queue: %d, Pool size: %d, Rejected: %d",
				executor.getActiveCount(),
				executor.getQueue().size(),
				executor.getPoolSize(),
				rejectedRequests.get()
			);

			exchange.sendResponseHeaders(200, stats.length());
			OutputStream os = exchange.getResponseBody();
			os.write(stats.getBytes());
			os.close();
		});

		server.start();
		System.out.println("ğŸš€ Serveur dÃ©marrÃ© sur http://localhost:8080");
		System.out.println("   Thread pool: 5 threads");
		System.out.println("   Queue: 10 requÃªtes max");
		System.out.println("   CapacitÃ© totale: 15 requÃªtes simultanÃ©es");
		System.out.println();
		System.out.println("ğŸ“ Endpoints:");
		System.out.println("   GET http://localhost:8080/api/data");
		System.out.println("   GET http://localhost:8080/stats");
	}
}
```

```java

import java.net.URI;
import java.net.http.HttpClient;
import java.net.http.HttpRequest;
import java.net.http.HttpResponse;
import java.time.Duration;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

public class BadGuyWithLotOfRequestToDo {

	private static final String SERVER_URL = "http://localhost:8080/api/data";
	private static final int TOTAL_REQUESTS = 20; // 15 capacitÃ©s + 5 rejets

	private static final AtomicInteger successCount = new AtomicInteger(0);
	private static final AtomicInteger errorCount = new AtomicInteger(0);

	public static void main(String[] args) throws InterruptedException {
		HttpClient httpClient = HttpClient.newBuilder()
			.connectTimeout(Duration.ofSeconds(10))
			.build();

		ExecutorService executor = Executors.newFixedThreadPool(20);

		System.out.println("ğŸš€ Envoi de " + TOTAL_REQUESTS + " requÃªtes simultanÃ©es...");
		System.out.println("â±ï¸  CapacitÃ© serveur: 5 threads + 10 queue = 15 max");
		System.out.println();

		long startTime = System.currentTimeMillis();

		for (int i = 1; i <= TOTAL_REQUESTS; i++) {
			final int requestId = i;
			executor.submit(() -> {
				try {
					HttpRequest request = HttpRequest.newBuilder()
						.uri(URI.create(SERVER_URL))
						.GET()
						.build();

					HttpResponse<String> response = httpClient.send(
						request,
						HttpResponse.BodyHandlers.ofString()
					);

					if (response.statusCode() == 200) {
						successCount.incrementAndGet();
						System.out.printf("âœ… RequÃªte #%d OK (Thread: %s)%n",
							requestId, Thread.currentThread().getName());
					}
				} catch (Exception e) {
					errorCount.incrementAndGet();
					System.err.printf("âŒ RequÃªte #%d ERREUR: %s%n",
						requestId, e.getMessage());
				}
			});
		}

		executor.shutdown();
		executor.awaitTermination(1, TimeUnit.MINUTES);

		long duration = System.currentTimeMillis() - startTime;

		System.out.println("\nğŸ“Š RÃ©sultats:");
		System.out.println("   SuccÃ¨s: " + successCount.get());
		System.out.println("   Erreurs: " + errorCount.get());
		System.out.println("   DurÃ©e: " + duration + " ms");

		if (errorCount.get() > 0) {
			System.out.println("\nâš ï¸  Serveur saturÃ© ! Des requÃªtes ont Ã©tÃ© rejetÃ©es.");
		}
	}

}
```

Cette exemple dÃ©montre clairement les limitations d'une architecture Thread-per-Request classique :
 - Le serveur ne peut gÃ©rer qu'un nombre limitÃ© de requÃªtes simultanÃ©es (15 dans cet exemple, volontairement bas).
 - Lorsque la charge dÃ©passe cette limite, les requÃªtes supplÃ©mentaires sont rejetÃ©es.
---

## 3.2 Le coÃ»t du Context Switching intensif (POUR APPROFONDIR)

### Benchmark : Impact du nombre de threads

```java
import java.util.concurrent.*;
import java.util.List;
import java.util.ArrayList;

public class ContextSwitchingBenchmark {

	public static void main(String[] args) throws InterruptedException {

		System.out.println("=== Benchmark Context Switching ===\n");

		//On essaye de voir le temps de latence de traitement sur diffÃ©rents jalons
		int[] threadCounts = {10, 50, 100, 500, 1000, 5000, 10_000};

		System.out.println("DurÃ©e : Temps total (en millisecondes) pour que tous les threads terminent leur travail (calculs simple dans la boucle).");
		System.out.println("OpÃ©rtion/sec : Nombre total dâ€™opÃ©rations (incrÃ©ments dans toutes les boucles) divisÃ© par la durÃ©e du test en secondes. mesure finalement le dÃ©bit du systÃ¨me");
		System.out.println("Overhead : Indicateur de surcharge basÃ© sur le nombre de threads par rapport aux cÅ“urs disponibles.");

		for (int numThreads : threadCounts) {
			benchmarkWithThreads(numThreads);
		}

	}

	private static void benchmarkWithThreads(int numThreads)
		throws InterruptedException {

		CountDownLatch startLatch = new CountDownLatch(1);
		CountDownLatch doneLatch = new CountDownLatch(numThreads);

		int incrementsPerThread = 100_000;

		List<Thread> threads = new ArrayList<>();

		// On commence par crÃ©er les threads
		for (int i = 0; i < numThreads; i++) {
			Thread t = new Thread(() -> {
				try {
					startLatch.await();

					//Juste un calcul pour simuler du travail
					long sum = 0;
					for (int j = 0; j < incrementsPerThread; j++) {
						sum += j;
					}

				} catch (InterruptedException e) {
					Thread.currentThread().interrupt();
				} finally {
					doneLatch.countDown();
				}
			});
			t.start();
			threads.add(t);
		}

		Thread.sleep(100);

		// Ici on dÃ©marre tous les threads
		long startTime = System.nanoTime();
		startLatch.countDown();

		doneLatch.await();
		long duration = System.nanoTime() - startTime;

		//On essaye de calculer un dÃ©bit d'opÃ©rations
		long totalOperations = (long) numThreads * incrementsPerThread;
		double durationMs = duration / 1_000_000.0;
		double opsPerSec = totalOperations / (duration / 1_000_000_000.0);

		System.out.printf("Threads: %5d | DurÃ©e: %7.0f ms | " +
				"OpÃ©rations/sec: %12.0f | Overhead: %s%n",
			numThreads, durationMs, opsPerSec,
			getOverheadIndicator(numThreads)
		);

		// finito pipo ricardo
		for (Thread t : threads) {
			t.join();
		}
	}

	private static String getOverheadIndicator(int numThreads) {
		int cores = Runtime.getRuntime().availableProcessors();
		if (numThreads <= cores) return "âœ“ Optimal";
		if (numThreads <= cores * 2) return "âš  Acceptable";
		if (numThreads <= cores * 10) return "âš âš  Ã‰levÃ©";
		return "âŒ Critique";
	}
}

```
---

### Impact sur les architectures modernes

```
Application Microservice moderne:

Besoins rÃ©els:
â€¢ API Gateway: 10,000 connexions simultanÃ©es
â€¢ User Service: 5,000 connexions
â€¢ Order Service: 3,000 connexions
â€¢ Payment Service: 2,000 connexions
Total: 20,000 connexions simultanÃ©es

Avec Platform Threads:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway                            â”‚
â”‚ â€¢ 200 threads â†’ 200 connexions max     â”‚
â”‚ â€¢ Les 9,800 autres en QUEUE            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Service                           â”‚
â”‚ â€¢ 200 threads â†’ 200 connexions max     â”‚
â”‚ â€¢ Les 4,800 autres en QUEUE            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Solution actuelle (coÃ»teuse):
â€¢ Horizontal Scaling: 50 instances pour Gateway
â€¢ 25 instances pour User Service
â€¢ CoÃ»t cloud: $$$$$
â€¢ ComplexitÃ©: Load balancing, orchestration
```

---

## 3.3 I/O Bloquant : Le grand gaspillage (Pour approfondir)

### Analyse d'une application rÃ©elle

```java
import java.sql.*;
import java.net.URI;
import java.net.http.*;
import java.time.Duration;

public class RealWorldScenario {
    
    private static final HttpClient httpClient = HttpClient.newHttpClient();
    
    public static void main(String[] args) throws Exception {
        
        System.out.println("=== Simulation application rÃ©elle ===\n");
        
        // Profiler une requÃªte typique
        profileRequest();
    }
    
    private static void profileRequest() throws Exception {
        
        long totalStart = System.nanoTime();
        long lastCheckpoint = totalStart;
        
        System.out.println("[Phase 1] Validation paramÃ¨tres");
        Thread.sleep(5); // Simulation
        printDuration("Validation", lastCheckpoint);
        lastCheckpoint = System.nanoTime();
        
        System.out.println("\n[Phase 2] RequÃªte base de donnÃ©es");
        // Simulation JDBC
        Thread.sleep(50);
        printDuration("DB Query", lastCheckpoint);
        lastCheckpoint = System.nanoTime();
        
        System.out.println("\n[Phase 3] Appel API externe (auth)");
        // Simulation HTTP
        Thread.sleep(120);
        printDuration("Auth API", lastCheckpoint);
        lastCheckpoint = System.nanoTime();
        
        System.out.println("\n[Phase 4] Traitement business logic");
        Thread.sleep(10);
        printDuration("Business Logic", lastCheckpoint);
        lastCheckpoint = System.nanoTime();
        
        System.out.println("\n[Phase 5] RequÃªte cache (Redis)");
        Thread.sleep(15);
        printDuration("Cache", lastCheckpoint);
        lastCheckpoint = System.nanoTime();
        
        System.out.println("\n[Phase 6] Appel API externe (notification)");
        Thread.sleep(80);
        printDuration("Notification API", lastCheckpoint);
        lastCheckpoint = System.nanoTime();
        
        System.out.println("\n[Phase 7] SÃ©rialisation rÃ©ponse");
        Thread.sleep(5);
        printDuration("Serialization", lastCheckpoint);
        
        long totalDuration = System.nanoTime() - totalStart;
        
        System.out.println("\n" + "=".repeat(50));
        System.out.println("DURÃ‰E TOTALE: " + totalDuration / 1_000_000 + " ms");
        System.out.println("=".repeat(50));
        
        // Analyse
        analyzeEfficiency();
    }
    
    private static void printDuration(String phase, long lastCheckpoint) {
        long duration = (System.nanoTime() - lastCheckpoint) / 1_000_000;
        System.out.printf("  âœ“ %s: %d ms%n", phase, duration);
    }
    
    private static void analyzeEfficiency() {
        System.out.println("\nAnalyse d'efficacitÃ©:");
        System.out.println("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
        System.out.println("â”‚ Phase                   â”‚ DurÃ©e    â”‚ Type       â”‚");
        System.out.println("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        System.out.println("â”‚ Validation              â”‚    5 ms  â”‚ CPU âœ“      â”‚");
        System.out.println("â”‚ DB Query                â”‚   50 ms  â”‚ I/O âš       â”‚");
        System.out.println("â”‚ Auth API                â”‚  120 ms  â”‚ I/O âš       â”‚");
        System.out.println("â”‚ Business Logic          â”‚   10 ms  â”‚ CPU âœ“      â”‚");
        System.out.println("â”‚ Cache                   â”‚   15 ms  â”‚ I/O âš       â”‚");
        System.out.println("â”‚ Notification API        â”‚   80 ms  â”‚ I/O âš       â”‚");
        System.out.println("â”‚ Serialization           â”‚    5 ms  â”‚ CPU âœ“      â”‚");
        System.out.println("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        System.out.println("â”‚ TOTAL                   â”‚  285 ms  â”‚            â”‚");
        System.out.println("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
        
        System.out.println("\nğŸ“Š RÃ©partition:");
        System.out.println("  â€¢ Temps CPU actif:  20 ms (  7%)  â† Travail utile");
        System.out.println("  â€¢ Temps I/O bloquÃ©: 265 ms ( 93%)  â† GASPILLAGE!");
        
        System.out.println("\nâš ï¸  ProblÃ¨me:");
        System.out.println("  Le thread Platform reste BLOQUÃ‰ pendant 265ms");
        System.out.println("  â†’ 2 MB de mÃ©moire inutilisÃ©s");
        System.out.println("  â†’ 1 slot du thread pool monopolisÃ©");
        System.out.println("  â†’ CPU idle");
        
        System.out.println("\nğŸ’¡ Avec 200 threads Platform:");
        System.out.println("  â€¢ Si 200 requÃªtes arrivent simultanÃ©ment");
        System.out.println("  â€¢ 200 threads tous BLOQUÃ‰S 93% du temps");
        System.out.println("  â€¢ CPU utilization: ~7%");
        System.out.println("  â€¢ Mais impossible d'accepter plus de requÃªtes!");
    }
}

/* Output:

=== Simulation application rÃ©elle ===

[Phase 1] Validation paramÃ¨tres
  âœ“ Validation: 5 ms

[Phase 2] RequÃªte base de donnÃ©es
  âœ“ DB Query: 50 ms

[Phase 3] Appel API externe (auth)
  âœ“ Auth API: 120 ms

[Phase 4] Traitement business logic
  âœ“ Business Logic: 10 ms

[Phase 5] RequÃªte cache (Redis)
  âœ“ Cache: 15 ms

[Phase 6] Appel API externe (notification)
  âœ“ Notification API: 80 ms

[Phase 7] SÃ©rialisation rÃ©ponse
  âœ“ Serialization: 5 ms

==================================================
DURÃ‰E TOTALE: 285 ms
==================================================

Analyse d'efficacitÃ©:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase                   â”‚ DurÃ©e    â”‚ Type       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Validation              â”‚    5 ms  â”‚ CPU âœ“      â”‚
â”‚ DB Query                â”‚   50 ms  â”‚ I/O âš       â”‚
â”‚ Auth API                â”‚  120 ms  â”‚ I/O âš       â”‚
â”‚ Business Logic          â”‚   10 ms  â”‚ CPU âœ“      â”‚
â”‚ Cache                   â”‚   15 ms  â”‚ I/O âš       â”‚
â”‚ Notification API        â”‚   80 ms  â”‚ I/O âš       â”‚
â”‚ Serialization           â”‚    5 ms  â”‚ CPU âœ“      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL                   â”‚  285 ms  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“Š RÃ©partition:
  â€¢ Temps CPU actif:  20 ms (  7%)  â† Travail utile
  â€¢ Temps I/O bloquÃ©: 265 ms ( 93%)  â† GASPILLAGE!

âš ï¸  ProblÃ¨me:
  Le thread Platform reste BLOQUÃ‰ pendant 265ms
  â†’ 2 MB de mÃ©moire inutilisÃ©s
  â†’ 1 slot du thread pool monopolisÃ©
  â†’ CPU idle

ğŸ’¡ Avec 200 threads Platform:
  â€¢ Si 200 requÃªtes arrivent simultanÃ©ment
  â€¢ 200 threads tous BLOQUÃ‰S 93% du temps
  â€¢ CPU utilization: ~7%
  â€¢ Mais impossible d'accepter plus de requÃªtes!
*/
```

---

## 3.4 Cas d'usage critiques (Pour approfondir)

### 3.4.1 WebSocket et Connexions longues

```java
import javax.websocket.*;
import javax.websocket.server.ServerEndpoint;
import java.util.Set;
import java.util.concurrent.CopyOnWriteArraySet;

@ServerEndpoint("/chat")
public class ChatWebSocket {
    
    private static final Set<Session> sessions = new CopyOnWriteArraySet<>();
    
    @OnOpen
    public void onOpen(Session session) {
        sessions.add(session);
        System.out.println("Nouvelle connexion: " + session.getId());
        System.out.println("Connexions actives: " + sessions.size());
        
        // PROBLÃˆME CRITIQUE:
        // Chaque connexion WebSocket = 1 thread Platform BLOQUÃ‰
        // Le thread reste ouvert tant que la connexion est active
        // Un websocket reste ouvert sur des pÃ©riodes de temps extrÃªmement longue 
        
        // Avec 200 threads max:
        // 200 connexions WebSocket = thread pool SATURÃ‰
        // â†’ Plus aucune requÃªte HTTP ne peut Ãªtre traitÃ©e!
    }
    
    @OnMessage
    public void onMessage(String message, Session session) {
        sessions.forEach(s -> {
            try {
                s.getBasicRemote().sendText(message);
            } catch (Exception e) {
                e.printStackTrace();
            }
        });
    }
    
    @OnClose
    public void onClose(Session session) {
        sessions.remove(session);
        System.out.println("Connexion fermÃ©e: " + session.getId());
        System.out.println("Connexions restantes: " + sessions.size());
    }
}

/*
ScÃ©nario catastrophe:

1. Serveur avec 200 threads Platform
2. 150 clients WebSocket se connectent
3. â†’ 150 threads Platform BLOQUÃ‰S indÃ©finiment
4. â†’ Il reste 50 threads pour les requÃªtes HTTP
5. â†’ Si 50+ requÃªtes HTTP arrivent â†’ QUEUE
6. â†’ Latence explose pour les requÃªtes normales

Solution actuelle: Serveur dÃ©diÃ© pour WebSocket
CoÃ»t: Infrastructure additionnelle, complexitÃ©
*/
```

### 3.4.2 Traitement Batch massivement parallÃ¨le (Pour approfondir)

```java
import java.util.List;
import java.util.ArrayList;
import java.util.concurrent.*;

public class BatchProcessingProblem {
    
    public static void main(String[] args) throws Exception {
        
        // ScÃ©nario: Traiter 100,000 enregistrements comme on pourrait le faire en entreprise sur un batch
        List<Integer> records = new ArrayList<>();
        for (int i = 0; i < 100_000; i++) {
            records.add(i);
        }
        
        System.out.println("Approche 1: Pool fixe de 50 threads");
        long start = System.currentTimeMillis();
        
        ExecutorService executor = Executors.newFixedThreadPool(50);
        List<Future<String>> futures = new ArrayList<>();
        
        for (Integer record : records) {
            futures.add(executor.submit(() -> processRecord(record)));
        }
        
        for (Future<String> future : futures) {
            future.get();
        }
        
        executor.shutdown();
        long duration1 = System.currentTimeMillis() - start;
        
        System.out.println("Temps: " + duration1 + " ms");
        System.out.println("Throughput: " + (100_000.0 / duration1 * 1000) + " records/sec");
        
       System.out.println("\n---------------------------------------------------");
       System.out.println("\n---------------------------------------------------");
        System.out.println("\nApproche 2: Pool de 500 threads");
        start = System.currentTimeMillis();
        
        executor = Executors.newFixedThreadPool(500);
        futures = new ArrayList<>();
        
        for (Integer record : records) {
            futures.add(executor.submit(() -> processRecord(record)));
        }
        
        for (Future<String> future : futures) {
            future.get();
        }
        
        executor.shutdown();
        long duration2 = System.currentTimeMillis() - start;
        
        System.out.println("Temps: " + duration2 + " ms");
        System.out.println("Throughput: " + (100_000.0 / duration2 * 1000) + " records/sec");
        
        
        System.out.println("\n=== Analyse ===");
        System.out.println("50 threads:  " + duration1 + " ms");
        System.out.println("500 threads: " + duration2 + " ms");
        
        if (duration2 < duration1) {
            double improvement = ((duration1 - duration2) / (double) duration1) * 100;
            System.out.println("AmÃ©lioration: " + String.format("%.1f", improvement) + "%");
        } else {
            System.out.println("Plus de threads = PLUS LENT!");
            System.out.println("Raison: Context switching overhead > gain parallÃ©lisme");
        }
        
        System.out.println("\n ProblÃ¨me:");
        System.out.println("â€¢ 500 threads = 1 GB de mÃ©moire (stack)");
        System.out.println("â€¢ Context switching intensif");
        System.out.println("â€¢ Pas scalable Ã  1 million de records");
    }
    
    private static String processRecord(int recordId) {
        try {
            // Simulation: I/O bloquant (DB write, API call)
            Thread.sleep(100);
            return "Processed: " + recordId;
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
            return "Error: " + recordId;
        }
    }
}

/* Output typique:

=== Traitement avec Platform Threads ===

Approche 1: Pool fixe de 50 threads
Temps: 200800 ms (â‰ˆ 3min 20s)
Throughput: 498.0 records/sec

Approche 2: Pool de 500 threads
Temps: 21200 ms (â‰ˆ 21s)
Throughput: 4716.9 records/sec

=== Analyse ===
50 threads:  200800 ms
500 threads: 21200 ms
AmÃ©lioration: 89.4%

ProblÃ¨me:
â€¢ 500 threads = 1 GB de mÃ©moire (stack)
â€¢ Context switching intensif
â€¢ Pas scalable Ã  1 million de records

Avec 1 million de records:
â€¢ 500 threads â†’ 200+ secondes
â€¢ Pour aller plus vite â†’ plus de threads
â€¢ Mais 5000 threads = OutOfMemoryError!
*/
```

### 3.4.3 Microservices avec appels en cascade (Pour approfondir)

```java
import java.net.http.*;
import java.net.URI;
import java.util.concurrent.*;

public class MicroserviceCascade {
    
    private static final HttpClient httpClient = HttpClient.newHttpClient();
    
    public static void main(String[] args) throws Exception {
        
        System.out.println("=== Simulation cascade microservices ===\n");
        
        // Service A appelle Service B qui appelle Service C
        String result = serviceA();
        System.out.println("RÃ©sultat: " + result);
    }
    
    // Service A: API Gateway
    private static String serviceA() throws Exception {
        System.out.println("[Service A] RequÃªte reÃ§ue");
        long start = System.nanoTime();
        
        // Appel Service B (bloque le thread)
        String resultB = serviceB();
        
        // Traitement
        Thread.sleep(10);
        
        long duration = (System.nanoTime() - start) / 1_000_000;
        System.out.println("[Service A] TerminÃ© en " + duration + "ms");
        
        return "A(" + resultB + ")";
    }
    
    // Service B: User Service
    private static String serviceB() throws Exception {
        System.out.println("  [Service B] RequÃªte reÃ§ue");
        long start = System.nanoTime();
        
        // Appel Service C (bloque le thread)
        String resultC = serviceC();
        
        // Traitement
        Thread.sleep(15);
        
        long duration = (System.nanoTime() - start) / 1_000_000;
        System.out.println("  [Service B] TerminÃ© en " + duration + "ms");
        
        return "B(" + resultC + ")";
    }
    
    // Service C: Database Service
    private static String serviceC() throws Exception {
        System.out.println("    [Service C] RequÃªte reÃ§ue");
        long start = System.nanoTime();
        
        // RequÃªte DB (bloque le thread)
        Thread.sleep(80);
        
        long duration = (System.nanoTime() - start) / 1_000_000;
        System.out.println("    [Service C] TerminÃ© en " + duration + "ms");
        
        return "C(data)";
    }
}

/* Output:

=== Simulation cascade microservices ===

[Service A] RequÃªte reÃ§ue
  [Service B] RequÃªte reÃ§ue
    [Service C] RequÃªte reÃ§ue
    [Service C] TerminÃ© en 80ms
  [Service B] TerminÃ© en 95ms
[Service A] TerminÃ© en 105ms
RÃ©sultat: A(B(C(data)))

Analyse du problÃ¨me:

Timeline des threads:

Service A thread: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆ]
                   â–²                                  â–²
                   Actif                           Actif
                   â”‚â† BloquÃ© en attente Service B â†’â”‚

Service B thread: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆ]
                   â–²                            â–²
                   Actif                     Actif
                   â”‚â† BloquÃ© attente Service C â†’â”‚

Service C thread: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆ]
                   â–²                        â–²
                   Actif                 Actif
                   â”‚â† BloquÃ© sur DB â†’â”‚

ProblÃ¨me:
â€¢ 3 threads Platform mobilisÃ©s pour 1 requÃªte
â€¢ Chaque thread bloquÃ© 90% du temps
â€¢ Avec 1000 requÃªtes simultanÃ©es â†’ 3000 threads!
â€¢ OutOfMemoryError garanti

Impact production:
Service A: 200 threads â†’ max 200 requÃªtes/sec
Service B: 200 threads â†’ max 200 requÃªtes/sec
Service C: 200 threads â†’ max 200 requÃªtes/sec

Si Service C est lent (spike de latence):
â†’ Tous les threads de A et B se bloquent
â†’ Effet domino sur toute l'architecture
â†’ Timeout en cascade
*/
```

---

## 3.5 Les "Solutions" actuelles et leurs limites

### 3.5.1 Augmenter le nombre de threads

```java
// Configuration Tomcat typique
server.tomcat.threads.max=1000  // Au lieu de 200

/* ProblÃ¨mes:
Consommation mÃ©moire: 1000 Ã— 2MB = 2GB juste pour les stacks
Context switching: Performance dÃ©gradÃ©e
Toujours une limite: 1000 threads = 1000 connexions max
Si 2000 requÃªtes simultanÃ©es â†’ toujours un problÃ¨me!
Ne scale pas indÃ©finiment (OutOfMemoryError)

RÃ©sultat:
â€¢ CoÃ»t mÃ©moire Ã©levÃ©
â€¢ Performance dÃ©gradÃ©e (context switching)
â€¢ ProblÃ¨me non rÃ©solu, juste retardÃ©
*/
```

### 3.5.2 Programmation RÃ©active (WebFlux)

```java
// Avec Reactor (WebFlux)
public Mono<OrderDetails> getOrderDetails(Long orderId) {
    return orderRepository.findById(orderId)
        .flatMap(order -> 
            Mono.zip(
                userService.getUser(order.getUserId()),
                paymentService.getPayment(orderId),
                inventoryService.checkStock(orderId)
            ).map(tuple -> new OrderDetails(
                order,
                tuple.getT1(),
                tuple.getT2(),
                tuple.getT3()
            ))
        );
}

/* Avantages:
- Non-bloquant: excellent throughput
- Peu de threads nÃ©cessaires
- Scale trÃ¨s bien

InconvÃ©nients:
- Courbe d'apprentissage TRÃˆS raide
- Debugging cauchemardesque:
   Stack traces incomprÃ©hensibles avec 50 niveaux
- "Viral": tout le code doit devenir rÃ©actif
   Si une lib n'est pas rÃ©active â†’ bloque tout
- Code complexe pour des opÃ©rations simples
- NÃ©cessite drivers rÃ©actifs (R2DBC vs JDBC)
- Beaucoup de libs Java ne supportent pas le rÃ©actif
- Gestion d'erreur complexe
*/
```

### 3.5.3 Async/CompletableFuture

```java
// Avec CompletableFuture
public CompletableFuture<OrderDetails> getOrderDetails(Long orderId) {
    return orderRepository.findByIdAsync(orderId)
        .thenCompose(order -> 
            CompletableFuture.allOf(
                userService.getUserAsync(order.getUserId()),
                paymentService.getPaymentAsync(orderId)
            ).thenApply(v -> new OrderDetails(order, /*...*/ ))
        );
}

/* Avantages:
- Non-bloquant
- API standard Java
- Meilleur que les threads bloquants

InconvÃ©nients:
- Code verbeux et complexe
- Gestion erreur difficile (exceptionally, handle)
- Composition compliquÃ©e (thenCompose, thenCombine, etc.)
- Debug difficile
- Toujours limitÃ© par le thread pool sous-jacent
- "Viral": propage la complexitÃ©

Exemple de code pour 3 appels parallÃ¨les + 1 sÃ©quentiel:
CompletableFuture.supplyAsync(() -> getUser())
    .thenCompose(user -> 
        CompletableFuture.allOf(
            CompletableFuture.supplyAsync(() -> getOrders(user)),
            CompletableFuture.supplyAsync(() -> getPayments(user)),
            CompletableFuture.supplyAsync(() -> getPreferences(user))
        ).thenApply(v -> combine(user, ...))
    ).exceptionally(ex -> handleError(ex))
     .thenAccept(result -> sendResponse(result));

Code synchrone Ã©quivalent :
User user = getUser();
Orders orders = getOrders(user);
Payments payments = getPayments(user);
Preferences prefs = getPreferences(user);
Result result = combine(user, orders, payments, prefs);
sendResponse(result);


*/
```

### 3.5.4 Horizontal Scaling (plus de serveurs)

```
Solution actuelle en production:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Balancer                            â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”œâ”€â–º Instance 1 (200 threads)
      â”œâ”€â–º Instance 2 (200 threads)
      â”œâ”€â–º Instance 3 (200 threads)
      â”œâ”€â–º Instance 4 (200 threads)
      â”œâ”€â–º Instance 5 (200 threads)
      â”œâ”€â–º ... (50 instances)
      â””â”€â–º Instance 50 (200 threads)

Total: 10,000 threads "effectifs"
CoÃ»t: 50 instances EC2 m5.xlarge
Prix: ~$3,500/mois sur AWS

/* ProblÃ¨mes:
- CoÃ»t Ã©levÃ©: $42,000/an
- ComplexitÃ©: Load balancing, orchestration, monitoring
- Latence: Session affinity, cross-instance calls
- Waste: Chaque instance sous-utilisÃ©e (CPU Ã  10%)
- Management: DÃ©ploiements, mises Ã  jour, scaling

Alternative avec Virtual Threads:
- 5 instances seulement (mÃªme capacitÃ©)
- CoÃ»t: ~$350/mois ($4,200/an)
- Ã‰conomie: $37,800/an (90% de rÃ©duction!)
- ComplexitÃ© rÃ©duite
- Meilleure utilisation CPU (70-80%)
*/
```

---

## 3.6 Tableau rÃ©capitulatif des limitations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Limitations des Platform Threads                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Limitation          â”‚ Impact                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MÃ©moire             â”‚ â€¢ 2 MB par thread                         â”‚
â”‚                     â”‚ â€¢ Max ~5000 threads (16GB RAM)            â”‚
â”‚                     â”‚ â€¢ OutOfMemoryError au-delÃ                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Context Switching   â”‚ â€¢ Overhead 10-70% avec 1000+ threads      â”‚
â”‚                     â”‚ â€¢ CPU time gaspillÃ©                       â”‚
â”‚                     â”‚ â€¢ Cache thrashing                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CrÃ©ation            â”‚ â€¢ 0.5-1 ms par thread                     â”‚
â”‚                     â”‚ â€¢ CoÃ»teux pour short-lived tasks          â”‚
â”‚                     â”‚ â€¢ Thread pools requis                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Blocking I/O        â”‚ â€¢ 70-95% du temps en attente              â”‚
â”‚                     â”‚ â€¢ Thread inutilisÃ© mais                   â”‚
â”‚                     â”‚      consomme des ressources              â”‚            
â”‚                     â”‚ â€¢ Throughput limitÃ©                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ScalabilitÃ©         â”‚ â€¢ Thread-per-request â†’ max connections    â”‚
â”‚                     â”‚ â€¢ WebSocket â†’ thread pool saturation      â”‚
â”‚                     â”‚ â€¢ Batch processing limitÃ©                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CoÃ»t Cloud          â”‚ â€¢ Horizontal scaling coÃ»teux              â”‚
â”‚                     â”‚ â€¢ Sous-utilisation CPU (10-20%)           â”‚
â”‚                     â”‚ â€¢ Gaspillage ressources                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
### Comparaison des "solutions"
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Solution            â”‚ ComplexitÃ©  â”‚ Performance â”‚ ScalabilitÃ©  â”‚ Maintenance â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Plus de threads     â”‚ BON         â”‚ PASSABLE    â”‚ MAUVAIS      â”‚ PASSABLE    â”‚
â”‚ (1000+ threads)     â”‚ Simple      â”‚ LimitÃ©      â”‚ OOM rapide   â”‚ Config      â”‚
â”‚                     â”‚             â”‚ context     â”‚              â”‚ difficile   â”‚
â”‚                     â”‚             â”‚ switching   â”‚              â”‚             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Thread Pools        â”‚ BON         â”‚ BON         â”‚ PASSABLE     â”‚ BON         â”‚
â”‚ (fixed size)        â”‚ Standard    â”‚ RÃ©utilise   â”‚ Toujours     â”‚ APIs        â”‚
â”‚                     â”‚ Java        â”‚ threads     â”‚ limitÃ©       â”‚ simples     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CompletableFuture   â”‚ PASSABLE    â”‚ BON         â”‚ BON          â”‚ PASSABLE    â”‚
â”‚ (async)             â”‚ Verbeux     â”‚ Non-        â”‚ Pool sous-   â”‚ Callbacks   â”‚
â”‚                     â”‚ Callbacks   â”‚ bloquant    â”‚ jacent       â”‚ complexes   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Reactive (WebFlux)  â”‚ MAUVAIS     â”‚ EXCELLENT   â”‚ EXCELLENT    â”‚ MAUVAIS     â”‚
â”‚ Reactor/RxJava      â”‚ TrÃ¨s raide  â”‚ Throughput  â”‚ TrÃ¨s peu     â”‚ Debug       â”‚
â”‚                     â”‚ Viral       â”‚ maximal     â”‚ de threads   â”‚ difficile   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Horizontal          â”‚ PASSABLE    â”‚ BON         â”‚ EXCELLENT    â”‚ PASSABLE    â”‚
â”‚ Scaling             â”‚ Orchestr.   â”‚ LinÃ©aire    â”‚ Ajouter      â”‚ DÃ©ploiementsâ”‚
â”‚                     â”‚ nÃ©cessaire  â”‚             â”‚ instances    â”‚ multiples   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Virtual Threads     â”‚ EXCELLENT   â”‚ EXCELLENT   â”‚ EXCELLENT    â”‚ EXCELLENT   â”‚
â”‚ (Java 21)           â”‚ Code sync   â”‚ Non-        â”‚ Millions     â”‚ Code simple â”‚
â”‚                     â”‚ simple      â”‚ bloquant    â”‚ de threads   â”‚ Debug std   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

LÃ©gende:
â€¢ MAUVAIS : InadaptÃ© ou problÃ©matique
â€¢ PASSABLE : Fonctionne mais avec compromis
â€¢ BON : Satisfaisant pour la plupart des cas
â€¢ EXCELLENT : Optimal, sans compromis significatif
```

---


## 3.7 MÃ©triques rÃ©elles : Avant LTS21/25 et VT

### Application E-commerce typique

```
Profil d'une application e-commerce classique:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©triques Production (Platform Threads)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
â”‚ Infrastructure:                                â”‚
â”‚ â€¢ 20 instances EC2 m5.xlarge (4 vCPU, 16GB)    â”‚
â”‚ â€¢ Thread pool: 200 threads par instance        â”‚
â”‚ â€¢ Total: 4,000 threads "effectifs"             â”‚
â”‚                                                â”‚
â”‚ Performance:                                   â”‚
â”‚ â€¢ Peak load: 500 req/sec                       â”‚
â”‚ â€¢ Latence p50: 250ms                           â”‚
â”‚ â€¢ Latence p99: 1,200ms                         â”‚
â”‚ â€¢ CPU utilization: 15-25%                      â”‚
â”‚ â€¢ Memory usage: 60%                            â”‚
â”‚                                                â”‚
â”‚ CoÃ»ts mensuels:                                â”‚
â”‚ â€¢ EC2: 20 Ã— $70 = $1,400/mois                  â”‚
â”‚ â€¢ Load Balancer: $100/mois                     â”‚
â”‚ â€¢ Total: $1,500/mois                           â”‚
â”‚                                                â”‚
â”‚ ProblÃ¨mes:                                     â”‚
â”‚ â€¢ Sous-utilisation CPU massive (75% idle)      â”‚
â”‚ â€¢ Latence p99 Ã©levÃ©e (queueing)                â”‚
â”‚ â€¢ CoÃ»ts Ã©levÃ©s pour la capacitÃ© fournie        â”‚
â”‚ â€¢ Impossible de gÃ©rer plus de 500 req/sec      â”‚
â”‚   sans ajouter des instances                   â”‚
â”‚                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Analyse d'une journÃ©e type

```
Load profile sur 24h:

RequÃªtes/sec
    1000â”‚                    â•­â”€â•®
        â”‚                  â•­â”€â•¯ â•°â”€â•®
     500â”‚       â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯     â•°â”€â”€â”€â”€â•®
        â”‚     â•­â”€â•¯                     â•°â”€â•®
     250â”‚  â•­â”€â”€â•¯                         â•°â”€â”€â•®
        â”‚â•­â”€â•¯                               â•°â”€â•®
       0â””â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€
        0h  4h  8h  12h 16h 20h 24h

Observations:
â€¢ Peak: 16h-18h (rentrÃ©e bureau) â†’ 600 req/sec
â€¢ Avec 4,000 threads â†’ proche saturation
â€¢ Night: 0h-6h â†’ 50 req/sec
â€¢ 3,900 threads INUTILISÃ‰S mais coÃ»tent!

Avec Virtual Threads:
â€¢ MÃªme infrastructure
â€¢ Peut gÃ©rer 5,000+ req/sec
â€¢ CoÃ»t identique
â€¢ Ou: diviser par 10 le nombre d'instances
  â†’ $150/mois au lieu de $1,500/mois
```

---

## 3.8 RÃ©sumÃ© : Le mur des Platform Threads

### Les chiffres qui font mal

```
Limites dures des Platform Threads:

Avec Platform Threads, choisissez 2 sur 3:        â”‚
â”‚  â€¢ Simple + Performant = Pas scalable           â”‚
â”‚  â€¢ Scalable + Performant = Complexe (reactive)  â”‚
â”‚  â€¢ Simple + Scalable = Pas performant 

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©trique                 â”‚ Limite Platform  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Threads par machine      â”‚ ~5,000 max       â”‚
â”‚ Connexions simultanÃ©es   â”‚ ~5,000 max       â”‚
â”‚ MÃ©moire par thread       â”‚ 2 MB             â”‚
â”‚ Context switch overhead  â”‚ 10-70% (>1000)   â”‚
â”‚ Temps crÃ©ation           â”‚ 0.5 ms           â”‚
â”‚ EfficacitÃ© I/O bloquant  â”‚ 5-30% CPU usage  â”‚
â”‚ CoÃ»t horizontal scaling  â”‚ $$             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ce que Ã§a signifie en production:
- Impossible de gÃ©rer 100,000 connexions WebSocket
- Batch de 1M records â†’ 30+ minutes ou OOM
- Microservices â†’ cascade de blocages
- CPU idle Ã  90% mais "pas de capacitÃ©"
- CoÃ»ts cloud Ã— 10 pour compenser

La conclusion est claire:
Le modÃ¨le Platform Thread ne peut PAS scale
pour les applications modernes.

â¡ï¸  Solution: Virtual Threads (chapitre suivant)
```

### Points clÃ©s Ã  retenir

```
âœ… Ce qu'il faut retenir sur les limitations:

1. Thread-per-request ne scale pas
   â€¢ Max 5,000 connexions simultanÃ©es
   â€¢ Au-delÃ : queue ou crash
   
2. I/O bloquant = gaspillage massif
   â€¢ 70-95% du temps en attente
   â€¢ CPU idle mais capacitÃ© saturÃ©e
   
3. Context switching = overhead critique
   â€¢ >1,000 threads â†’ 50% overhead
   â€¢ Performance s'effondre
   
4. MÃ©moire = limite dure
   â€¢ 2 MB par thread
   â€¢ OutOfMemoryError inÃ©vitable
   
5. Les "solutions" actuelles ont des compromis
   â€¢ Reactive: complexe
   â€¢ Async: verbeux
   â€¢ Scaling: coÃ»teux
   
6. Le problÃ¨me est fondamental
   â€¢ Pas un bug Ã  fixer
   â€¢ Mais une limite architecturale
   â€¢ NÃ©cessite une nouvelle approche

Enfin nous y arrivons : Virtual Threads

   â€¢ Millions de threads possibles
   â€¢ Code simple (synchrone)
   â€¢ Performance excellente
   â€¢ Sans les compromis!
```

---

[ğŸ  Accueil](../index.md) | [ğŸ“‹ Sommaire](../sommaire.md) | [â¬…ï¸ PrÃ©cÃ©dent](02-jvm-platform-threads.md) | [â¡ï¸ Suivant: Introduction aux Virtual Threads](04-virtual-threads-intro.md)